{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Documentation for apitofsim","text":"<p>This is the documentation for apitofsim, a simulation of cluster fragmentation in an Atmospheric Pressure interface Time of Flight Mass Spectrometer (APi-ToF MS).</p>"},{"location":"#installation","title":"Installation","text":"<p>It is recommend to install this package using Conda. Users on Windows should use WSL. First download miniforge and then run:</p> <pre><code>conda install -c https://prefix.dev/vilma apitofsim\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>There are two main entry points to running the simulation: the Python API and the command line tools. The Python API is recommended for new users, and new functionality may only be available there.</p>"},{"location":"#python-api","title":"Python API","text":"<p>See Using the Python API.</p>"},{"location":"#command-line-tools","title":"Command line tools","text":"<p>If you have installed via Conda, and activated the relevant environment, the command line tools should be installed and in your path. If you have compiled the sources yourself, you will need to add build/src to your path for the following example to work. You can run the included example pathway like so:</p> <pre><code>apitofsim-skimmer &lt; inputs/example/config.in\napitofsim-densityandrate &lt; inputs/example/config.in\napitofsim-main &lt; inputs/example/config.in\n</code></pre> <p>Outputs are generated in <code>work/out</code> directory.</p>"},{"location":"#how-does-it-work","title":"How does it work?","text":"<p>The simulation runs a number of iterations with each one considering a single instance of a cluster travelling through and APi-TOF MS. The main simulation loop considers the distributions of the time until the next collision between the cluster and a gas molecules, the speed/angle of that collision, and the time until the cluster fragments. The main quantity of interest is the probability the cluster survives to reach the detector without fragmenting.</p>"},{"location":"#publications-describing-the-simulation","title":"Publications describing the simulation","text":"<p>The main principles of the simulation are described across a number of publications.</p> <p>Zapadinsky et al. (2019)<sup>1</sup> describe the simplest version of the simulation, in which only a single pressure and electric field are considered. Further information on the equations are given in the supporting information<sup>2</sup>. The main parts described are the overall scheme of simulation. The actual code used for this publication was written in Matlab and is not publicly available.</p> <p>Zanca et al. (2020)<sup>3</sup> describe a version of the simulation expanding the above to consider five zones. Zone I being the first chamber, II the skimmer, and III-V the second chamber, before, during and after the quadrupole respectively. This publication describes the simulation of the skimmer and quadrupole. The code used in this publication is an earlier version of the code in this repository.</p> <p>Later, Zanca, T. (2025)<sup>4</sup> added support for atom-like products.</p> <p>The current version of the code supports sampling schemes other than the originally described histogram-based technique. The rejection sampling method is described in one of the notebooks included in the source code repository.</p>"},{"location":"#publications-using-the-simulation","title":"Publications using the simulation","text":"<p>These publication make use (previous versions of) this simulation.</p> <p>TODO: Complete this section.</p>"},{"location":"#building-the-sources","title":"Building the sources","text":"<p>This section describes how to build the sources from scratch.</p>"},{"location":"#using-meson-to-compile-the-python-extension","title":"Using Meson to compile the Python extension","text":"<p>meson-python is used to build the Python extension.</p> <p>You need disable build isolation to install this as a development/editable package which will recompile at import:</p> <p>Using uv:</p> <pre><code>uv sync\nuv pip install --no-build-isolation -e .\n</code></pre> <p>During development you can also run the following to get compiler errors on import, and add debug symbols:</p> <pre><code>uv pip install --no-build-isolation --config-settings=editable-verbose=true -Csetup-args=\"-Dbuildtype=debugoptimized\" -Cbuild-dir=pydebugbuild -e .\n</code></pre>"},{"location":"#using-meson-to-compile-the-executables","title":"Using Meson to compile the executables","text":"<pre><code>meson setup --buildtype release build\nmeson compile -C build\n</code></pre> <p>The binaries are then in <code>build/src</code>. You add this directory to your PATH or symlink to them.</p> <p>This will also create a compilation database that <code>clangd</code> can use.</p> <p>There are debug and sanitize Meson \"native build configuration\" files using clang in <code>meson/clangdebug.ini</code> and <code>meson/clangsan.ini</code> respectively. On Linux, you may need to install <code>libc++</code> (from LLVM rather than GNU) e.g. <code>apt install 'libc++1' 'libc++-dev'</code>. For example:</p> <pre><code>meson setup --native-file meson/clangdebug.ini debugbuild\n</code></pre> <ol> <li> <p>Zapadinsky, E., Passananti, M., Myllys, N., Kurt\u00e9n, T., &amp; Vehkam\u00e4ki, H. (2019). Modeling on Fragmentation of Clusters inside a Mass Spectrometer. The Journal of Physical Chemistry. A, 123, 611 - 624. [web] [pdf] [doi] \u21a9</p> </li> <li> <p>Zapadinsky, E., Passananti, M., Myllys, N., Kurt\u00e9n, T., &amp; Vehkam\u00e4ki, H. (2019). Supporting Information to \"Modelling on Fragmentation of Clusters Inside a Mass Spectrometer\" [pdf] \u21a9</p> </li> <li> <p>Zanca, T., Kube\u010dka, J., Zapadinsky, E., Passananti, M., Kurt\u00e9n, T., &amp; Vehkam\u00e4ki, H. (2020). Highly oxygenated organic molecule cluster decomposition in atmospheric pressure interface time-of-flight mass spectrometers. Atmospheric Measurement Techniques, 13, 3581-3593. [web] [pdf] [doi] \u21a9</p> </li> <li> <p>Zanca, T. (2025). Note published online. [web] \u21a9</p> </li> </ol>"},{"location":"api/","title":"Using the Python API","text":"<p>This page documents the Python API. There is</p>"},{"location":"api/#main-api","title":"Main API","text":"<p>The main API is in the <code>apitofsim.api</code> module, re-exported from <code>apitofsim</code>.</p>"},{"location":"api/#data-classes","title":"Data classes","text":"<p>These classes hold data to be</p>"},{"location":"api/#simulation-functions","title":"Simulation functions","text":""},{"location":"api/#apitofsim.pinhole","title":"pinhole","text":"<pre><code>pinhole(\n    cluster_0: ClusterData,\n    cluster_1: ClusterData,\n    cluster_2: ClusterData,\n    gas: Gas,\n    density_cluster: Histogram,\n    rate_const: Histogram,\n    skimmer: ndarray,\n    lengths: MaybeQuantityArray,\n    voltages: MaybeQuantityArray,\n    T: MaybeQuantity,\n    pressure_first: MaybeQuantity,\n    pressure_second: MaybeQuantity,\n    N: int,\n    *,\n    sample_mode: int = 0,\n    loglevel: int = 0,\n    mesh_skimmer: float | None = None,\n    quadrupole: Quadrupole | None = None,\n    cluster_charge_sign: int = -1,\n    fragmentation_energy: MaybeQuantity | None = None,\n    seed: int = 42,\n    log_callback: Callable[[str, str], None] | None = None,\n    result_callback: Callable[[ndarray], None]\n    | None = None,\n    quantities_strict=True,\n)\n</code></pre> <p>This function runs the main simulation of the APi-ToF mass spectrometer.</p> Source code in <code>python/apitofsim/api.py</code> <pre><code>def pinhole(\n    cluster_0: ClusterData,\n    cluster_1: ClusterData,\n    cluster_2: ClusterData,\n    gas: Gas,\n    density_cluster: Histogram,\n    rate_const: Histogram,\n    skimmer: numpy.ndarray,\n    lengths: MaybeQuantityArray,\n    voltages: MaybeQuantityArray,\n    T: MaybeQuantity,\n    pressure_first: MaybeQuantity,\n    pressure_second: MaybeQuantity,\n    N: int,\n    *,\n    sample_mode: int = 0,\n    loglevel: int = 0,\n    mesh_skimmer: float | None = None,\n    quadrupole: Quadrupole | None = None,\n    cluster_charge_sign: int = -1,\n    fragmentation_energy: MaybeQuantity | None = None,\n    seed: int = 42,\n    log_callback: Callable[[str, str], None] | None = None,\n    result_callback: Callable[[numpy.ndarray], None] | None = None,\n    quantities_strict=True,\n):\n    \"\"\"\n    This function runs the main simulation of the APi-ToF mass spectrometer.\n    \"\"\"\n    process_arg = QuantityProcessor(quantities_strict)\n    lengths = process_arg(\"lengths\", lengths, \"meters\")\n    voltages = process_arg(\"voltages\", voltages, \"volts\")\n    T = process_arg(\"T\", T, \"kelvin\")\n    pressure_first = process_arg(\"pressure_first\", pressure_first, \"pascals\")\n    pressure_second = process_arg(\"pressure_second\", pressure_second, \"pascals\")\n    if fragmentation_energy is not None:\n        fragmentation_energy = process_arg(\n            \"fragmentation_energy\", fragmentation_energy, \"kelvin\"\n        )\n    if skimmer.shape[1] == 3:\n        if mesh_skimmer is None:\n            raise ValueError(\n                \"mesh_skimmer must be supplied when 3 column array is given for skimmer\"\n            )\n    elif skimmer.shape[1] == 6:\n        if mesh_skimmer is not None:\n            raise ValueError(\n                \"mesh_skimmer should not be supplied when 6 column array is given for skimmer\"\n            )\n        mesh_skimmer = float(skimmer[1, 0] - skimmer[0, 0])\n        skimmer = skimmer[:, 1:4]\n    else:\n        raise ValueError(\"skimmer must have 3 or 6 columns\")\n    return _pinhole(\n        cluster_0.into_cpp(),\n        cluster_1.into_cpp(),\n        cluster_2.into_cpp(),\n        gas.into_cpp(),\n        density_cluster.into_cpp(),\n        rate_const.into_cpp(),\n        skimmer,\n        mesh_skimmer,\n        lengths,\n        voltages,\n        T,\n        pressure_first,\n        pressure_second,\n        N,\n        fragmentation_energy=fragmentation_energy,\n        quadrupole=quadrupole and quadrupole.into_cpp(),\n        cluster_charge_sign=cluster_charge_sign,\n        seed=seed,\n        log_callback=log_callback,\n        result_callback=result_callback,\n        sample_mode=sample_mode,\n        loglevel=loglevel,\n    )\n</code></pre>"},{"location":"api/#apitofsim.densityandrate","title":"densityandrate","text":"<pre><code>densityandrate(\n    cluster_0: ClusterData,\n    cluster_1: ClusterData,\n    cluster_2: ClusterData,\n    energy_max: MaybeQuantity,\n    energy_max_rate: MaybeQuantity,\n    bin_width: MaybeQuantity,\n    fragmentation_energy: MaybeQuantity | None = None,\n    *,\n    quantities_strict=True,\n)\n</code></pre> <p>This function precomputes the density of states and rate constants histograms for a given set of clusters.</p> Source code in <code>python/apitofsim/api.py</code> <pre><code>def densityandrate(\n    cluster_0: ClusterData,\n    cluster_1: ClusterData,\n    cluster_2: ClusterData,\n    energy_max: MaybeQuantity,\n    energy_max_rate: MaybeQuantity,\n    bin_width: MaybeQuantity,\n    fragmentation_energy: MaybeQuantity | None = None,\n    *,\n    quantities_strict=True,\n):\n    \"\"\"\n    This function precomputes the density of states and rate constants histograms for a given set of clusters.\n    \"\"\"\n    process_arg = QuantityProcessor(quantities_strict)\n    energy_max = process_arg(\"energy_max\", energy_max, \"kelvin\")\n    energy_max_rate = process_arg(\"energy_max_rate\", energy_max_rate, \"kelvin\")\n    bin_width = process_arg(\"bin_width\", bin_width, \"kelvin\")\n    if fragmentation_energy is None:\n        fragmentation_energy = 0\n    else:\n        fragmentation_energy = process_arg(\n            \"fragmentation_energy\", fragmentation_energy, \"kelvin\"\n        )\n    density_cluster, rate_const = _densityandrate(\n        cluster_0.into_cpp(),\n        cluster_1.into_cpp(),\n        cluster_2.into_cpp(),\n        energy_max,\n        energy_max_rate,\n        bin_width,\n        fragmentation_energy,\n    )\n    return Histogram.from_cpp(density_cluster), Histogram.from_cpp(rate_const)\n</code></pre>"},{"location":"api/#apitofsim.skimmer","title":"skimmer","text":"<pre><code>skimmer(\n    T0: MaybeQuantity,\n    P0: MaybeQuantity,\n    rmax: MaybeQuantity,\n    dc: MaybeQuantity,\n    alpha_factor: MaybeQuantity,\n    gas: Gas | Gas,\n    N: int,\n    M: int,\n    resolution: int,\n    tolerance: float,\n    *,\n    output_pandas=False,\n    quantities_strict=True,\n)\n</code></pre> <p>This function precomputes various parameters including gas velocity, temperature and pressure at fixed points along the skimmer's' length.</p> Source code in <code>python/apitofsim/api.py</code> <pre><code>def skimmer(\n    T0: MaybeQuantity,\n    P0: MaybeQuantity,\n    rmax: MaybeQuantity,\n    dc: MaybeQuantity,\n    alpha_factor: MaybeQuantity,\n    gas: Gas | _Gas,\n    N: int,\n    M: int,\n    resolution: int,\n    tolerance: float,\n    *,\n    output_pandas=False,\n    quantities_strict=True,\n):\n    \"\"\"\n    This function precomputes various parameters including gas velocity, temperature and pressure at fixed points along the skimmer's' length.\n    \"\"\"\n    process_arg = QuantityProcessor(quantities_strict)\n    T0 = process_arg(\"T0\", T0, \"kelvin\")\n    P0 = process_arg(\"P0\", P0, \"pascal\")\n    rmax = process_arg(\"rmax\", rmax, \"meters\")\n    dc = process_arg(\"dc\", dc, \"meters\")\n    alpha_factor = process_arg(\"alpha_factor\", alpha_factor, \"halfturn\")\n    if isinstance(gas, Gas):\n        gas = gas.into_cpp()\n    out = _skimmer(T0, P0, rmax, dc, alpha_factor, gas, N, M, resolution, tolerance)\n    if output_pandas:\n        # Ignore this because Pandas' types are broken\n        return DataFrame(out, columns=SKIMMER_COLUMNS)  # pyright: ignore [reportArgumentType]\n    else:\n        return out\n</code></pre>"},{"location":"api/#database","title":"Database","text":"<p>The <code>apitofsim.db</code> module, contains functions to keep cluster data in a database, convenient for running scaled-up simulations.</p>"},{"location":"api/#apitofsim.db.ClusterDatabase","title":"ClusterDatabase","text":"<pre><code>ClusterDatabase(filename)\n</code></pre> Source code in <code>python/apitofsim/db.py</code> <pre><code>def __init__(self, filename):\n    self.db = duckdb.connect(filename)\n    self.cluster_cache = {}\n</code></pre>"},{"location":"api/#workflow-example-with-python","title":"Workflow example with Python","text":"<p>The following example shows how to run a full simulation workflow using Python scripts.</p> <p>To run this workflow, you must first obtain the data for [^1], which is currently available by request only.</p> <p>To run the workflow, create a file <code>config.json</code> pointing to the dataset:</p> <pre><code>{\n  \"path\": \"/path/to/data/100DMA-100SA/**/*.in\",\n  \"cwd\": \".\",\n  \"backup_search\": \"/path/to/data/QCData\"\n}\n</code></pre> <p>Then import the data using the provided script:</p> <pre><code>uv run prepare_data.py config.json prepared_data\n</code></pre> <p>You are now ready to run the workflow:</p> <pre><code>uv run run.py prepared_data\n</code></pre> <p>Plotting code will be provided later. This dataset may be published as open data at some point in the future.</p> <p>[1]: Alfaouri, D., Passananti, M., Zanca, T., Ahonen, L.R., Kangasluoma, J., Kube\u010dka, J., Myllys, N., &amp; Vehkam\u00e4ki, H. (2022). A study on the fragmentation of sulfuric acid and dimethylamine clusters inside an atmospheric pressure interface time-of-flight mass spectrometer. Atmospheric Measurement Techniques. [doi]</p> prepare.py<pre><code>import os\nfrom glob import glob\nfrom sys import argv\nfrom json import load\nfrom os import unlink\nimport pickle\nimport pint\n\nfrom apitofsim.db import ingest_legacy, ClusterDatabase\nfrom apitofsim.config import (\n    ConfigFile,\n    TOPLEVEL,\n)\n\n\nureg = pint.UnitRegistry()\nQ_ = ureg.Quantity\n\n\ndef main():\n    infn = argv[1]\n    out_path = argv[2]\n    db_name = out_path + \".duckdb\"\n    if os.path.exists(db_name):\n        unlink(db_name)\n    db = ClusterDatabase(db_name)\n    db.create_tables()\n\n    with open(infn) as f:\n        source = load(f)\n\n    ingest_legacy(db, source[\"path\"], source.get(\"backup_search\"))\n    filename = glob(source[\"path\"], recursive=True)[0]\n    config = ConfigFile(filename=filename)\n    common_config_out = {\n        k: config.get(k, by=\"short_name\")\n        for k in ([\"lengths\", \"voltages\", \"gas\"] + TOPLEVEL)\n    }\n    with open(out_path + \".pkl\", \"wb\") as outf:\n        pickle.dump(common_config_out, outf)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> run.py<pre><code>from os import environ\nimport sys\nimport pickle\nimport duckdb\nfrom apitofsim import (\n    skimmer,\n    densityandrate,\n    pinhole,\n    ClusterData,\n    ProductsCluster,\n    KTotalInput,\n    compute_density_of_states_batch,\n    compute_k_total_batch,\n    FragmentationPathway,\n)\nfrom apitofsim.db import ClusterDatabase\nfrom timeit import default_timer as timer\nimport pint\nfrom apitofsim.api import Histogram\n\n\nureg = pint.UnitRegistry()\nQ_ = ureg.Quantity\n\ndb = ClusterDatabase(sys.argv[1] + \".duckdb\")\nwith open(sys.argv[1] + \".pkl\", \"rb\") as inf:\n    config = pickle.load(inf)\n\ncluster_indexed, name_lookup = db.clusters_objects_indexed(include_name_lookup=True)\nprint()\n\nprint(\"Running skimmer\")\nskimmer_np = skimmer(\n    T0=config[\"T\"],\n    P0=config[\"pressure_first\"],\n    rmax=config[\"lengths\"][-1],\n    dc=config[\"dc\"],\n    alpha_factor=config[\"alpha_factor\"],\n    gas=config[\"gas\"],\n    N=config[\"N_iter\"],\n    M=config[\"M_iter\"],\n    resolution=config[\"resolution\"],\n    tolerance=config[\"tolerance\"],\n)\nprint(\"Done\")\n\nnum_pathways = 0\ndensity_of_states_inputs = []\nfor cluster, _, _ in db.pathways_objs(indexed=cluster_indexed):\n    density_of_states_inputs.append(cluster)\n    num_pathways += 1\n\nfor _, product1, product2 in db.pathways_objs(indexed=cluster_indexed):\n    density_of_states_inputs.append(ProductsCluster(product1, product2))\n\nprint(\"Computing density of states\")\nstart = timer()\n\ndensity_of_states = compute_density_of_states_batch(\n    density_of_states_inputs,\n    energy_max=config[\"energy_max\"],\n    bin_width=config[\"bin_width\"],\n)\nprint(f\"Done in {timer() - start}s\")\n\nprint(\"Got\")\nprint(density_of_states)\ncluster_dos = density_of_states[:, :num_pathways]\nproduct_dos = density_of_states[:, num_pathways:]\n\nk_total_inputs = []\nfor idx, (cluster, product1, product2) in enumerate(\n    db.pathways_objs(indexed=cluster_indexed)\n):\n    k_total_inputs.append(\n        KTotalInput(\n            product1.into_cpp(),\n            product2.into_cpp(),\n            FragmentationPathway(\n                cluster.into_cpp(), product1.into_cpp(), product2.into_cpp()\n            ).fragmentation_energy_kelvin(),\n            cluster_dos[:, idx],\n            product_dos[:, idx],\n        )\n    )\n\nprint(f\"Compute k total on {len(k_total_inputs)} inputs with mesh_mode=1\")\nstart = timer()\n\nk_rates = compute_k_total_batch(\n    k_total_inputs,\n    energy_max_rate=config[\"energy_max_rate\"],\n    bin_width=config[\"bin_width\"],\n    mesh_mode=1,\n)\n\nprint(f\"Done in {timer() - start}\")\nprint(\"Got\")\nprint(k_rates)\n\nfailures = 0\nfor (cluster_id, product1_id, product2_id), rate_const, density_cluster in zip(\n    db.pathways_ids(),\n    k_rates.T,\n    cluster_dos.T,\n):\n    cluster = cluster_indexed[cluster_id]\n    product1 = cluster_indexed[product1_id]\n    product2 = cluster_indexed[product2_id]\n    print(\n        f\"{name_lookup[cluster_id]} -&gt; {name_lookup[product1_id]} + {name_lookup[product2_id]}\"\n    )\n    density_hist = Histogram.from_mesh(\n        config[\"bin_width\"],\n        config[\"energy_max\"],\n        density_cluster,\n    )\n    rate_hist = Histogram.from_mesh(\n        config[\"bin_width\"],\n        config[\"energy_max_rate\"],\n        rate_const,\n    )\n    try:\n        result = pinhole(\n            cluster,\n            product1,\n            product2,\n            config[\"gas\"],\n            density_hist,\n            rate_hist,\n            skimmer_np,\n            config[\"lengths\"],\n            config[\"voltages\"],\n            config[\"T\"],\n            config[\"pressure_first\"],\n            config[\"pressure_second\"],\n            int(environ[\"N_OVERRIDE\"]) if \"N_OVERRIDE\" in environ else config[\"N\"],\n            quadrupole=config.get(\"quadrupole\"),\n            fragmentation_energy=config.get(\"fragmentation_energy\"),\n            cluster_charge_sign=config.get(\"cluster_charge_sign\", -1),\n            sample_mode=2,\n            loglevel=0,\n        )\n    except Exception as e:\n        failures += 1\n        print(f\"Error in simulation: {e}\")\n        continue\n    print(f\"Fragmented: {result[1]}, Escaped: {result[2]}\")\n\nprint(f\"Total failures: {failures} out of {num_pathways} pathways\")\n</code></pre>"},{"location":"notebooks/","title":"Running the notebooks","text":"<p>There are notebooks in the <code>examples/notebooks</code> directory.</p> <p>In order to run them, first download them from GitHub, and then install uv according to the linked instructions and then install marimo like so:</p> <pre><code>uv tool install marimo\n</code></pre> <p>You can then run a notebook using:</p> <pre><code>marimo edit --sandbox rejection-sampler-design.py\n</code></pre>"}]}